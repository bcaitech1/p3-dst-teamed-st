{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b776bae3-9ccd-4bb2-b853-0da959b081a0",
   "metadata": {},
   "source": [
    "# TRADE ì‹¤ìŠµ\n",
    "ğŸ˜ ë³¸ ë…¸íŠ¸ë¶ì€ TRADEë¥¼ í•œ ì¤„ ì”© ì‹¤í–‰í•˜ë©° Inputê³¼ Outputì˜ ì „ì²´ì ì¸ Flowë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ DST TRADE Model Taskì— ëŒ€í•´ ì˜¬ë°”ë¥¸ ì´í•´ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f46572-1655-4351-84aa-5242e259c963",
   "metadata": {},
   "source": [
    "### 1. TRADE_preprocessor\n",
    "convert examples to features (input_ids, segment_ids, target_ids, slot_meta) êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f7adc881-9b8e-467d-8cdd-726a23197f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertModel, BertTokenizer, AutoTokenizer, AutoModel\n",
    "from data_utils import *\n",
    "from preprocessor import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20168b5a-192e-4292-aa24-f5797ac8313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/code\n"
     ]
    }
   ],
   "source": [
    "cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "619bf92a-6480-4e85-b224-dfa53242d5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 3671.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word drop: 0.0\n",
      "í˜„ì¬ 2 ê°œì˜ ì£¼ì œì— ëŒ€í•´ ê°ê° í„´ìœ¼ë¡œ ì¶”ì¶œí•œ ì´ ëŒ€í™”ë°ì´í„°ì…‹ ê°œìˆ˜ : 12 ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#-> json íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ DSTInputExample ê°ì²´ ìƒì„±\n",
    "train_data, dev_data, dev_label = load_dataset(\"/opt/ml/input/data/train_dataset/train_dials.json\")\n",
    "with open(\"/opt/ml/input/data/train_dataset/slot_meta.json\") as f:\n",
    "    slot_meta = json.load(f)\n",
    "with open(\"/opt/ml/input/data/train_dataset/ontology.json\") as f:\n",
    "    ontology = json.load(f)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dsksd/bert-ko-small-minimal\")\n",
    "    \n",
    "#ëŒ€í™” 2ê°œ ì¶”ì¶œ, ë‹¨ í„´ì˜ ê¸¸ì´ëŠ” ê°ì ë‹¤ë¦„\n",
    "train_data = train_data[0:2]\n",
    "\n",
    "#ëŒ€í™”ë¥¼ í„´ ë³„ë¡œ DSTInputExample ê°ì²´ì— ë§ê²Œ ì¶”ì¶œ\n",
    "train_example = get_examples_from_dialogues(train_data)\n",
    "\n",
    "#tokenizing\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer)\n",
    "train_dataset = processor.convert_examples_to_features(train_example)\n",
    "print(f\"í˜„ì¬ {len(train_data)} ê°œì˜ ì£¼ì œì— ëŒ€í•´ ê°ê° í„´ìœ¼ë¡œ ì¶”ì¶œí•œ ì´ ëŒ€í™”ë°ì´í„°ì…‹ ê°œìˆ˜ : {len(train_dataset)} ê°œ\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4bf4eda2-0ae1-468a-be30-9352064ba92d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 178.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 12 ê°œì˜ featuresê°€ ìˆìŠµë‹ˆë‹¤\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[OpenVocabDSTFeature(guid='snowy-hat-8324:ê´€ê´‘_ì‹ë‹¹_11-0', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [8732, 3, 0], [21832, 11764, 3], [6265, 6672, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='snowy-hat-8324:ê´€ê´‘_ì‹ë‹¹_11-1', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='snowy-hat-8324:ê´€ê´‘_ì‹ë‹¹_11-2', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3, 6698, 4467, 4029, 4034, 9908, 26885, 11684, 25845, 4204, 10561, 18, 2373, 6289, 4279, 4147, 2054, 3249, 4154, 4161, 10397, 35, 3, 2279, 13090, 4192, 2024, 4112, 6249, 4234, 15532, 4403, 4292, 2010, 4219, 4451, 4112, 4244, 4150, 11431, 4221, 4007, 3249, 16868, 4479, 4150, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [93, 6756, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [15532, 4403, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='snowy-hat-8324:ê´€ê´‘_ì‹ë‹¹_11-3', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3, 6698, 4467, 4029, 4034, 9908, 26885, 11684, 25845, 4204, 10561, 18, 2373, 6289, 4279, 4147, 2054, 3249, 4154, 4161, 10397, 35, 3, 2279, 13090, 4192, 2024, 4112, 6249, 4234, 15532, 4403, 4292, 2010, 4219, 4451, 4112, 4244, 4150, 11431, 4221, 4007, 3249, 16868, 4479, 4150, 3, 6243, 4279, 4219, 12154, 27672, 4070, 3249, 4154, 4147, 27233, 35, 3, 3234, 18, 18, 8784, 4283, 27672, 4073, 3249, 4065, 4150, 35, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [8784, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [93, 6756, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [15532, 4403, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='snowy-hat-8324:ê´€ê´‘_ì‹ë‹¹_11-4', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3, 6698, 4467, 4029, 4034, 9908, 26885, 11684, 25845, 4204, 10561, 18, 2373, 6289, 4279, 4147, 2054, 3249, 4154, 4161, 10397, 35, 3, 2279, 13090, 4192, 2024, 4112, 6249, 4234, 15532, 4403, 4292, 2010, 4219, 4451, 4112, 4244, 4150, 11431, 4221, 4007, 3249, 16868, 4479, 4150, 3, 6243, 4279, 4219, 12154, 27672, 4070, 3249, 4154, 4147, 27233, 35, 3, 3234, 18, 18, 8784, 4283, 27672, 4073, 3249, 4065, 4150, 35, 3, 11946, 4279, 17164, 8784, 4283, 27672, 4073, 4034, 3123, 4154, 4114, 4116, 4150, 18, 3, 7258, 10238, 27672, 4239, 6304, 6722, 4076, 8553, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [10238, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [93, 6756, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [15532, 4403, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='snowy-hat-8324:ê´€ê´‘_ì‹ë‹¹_11-5', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3, 6698, 4467, 4029, 4034, 9908, 26885, 11684, 25845, 4204, 10561, 18, 2373, 6289, 4279, 4147, 2054, 3249, 4154, 4161, 10397, 35, 3, 2279, 13090, 4192, 2024, 4112, 6249, 4234, 15532, 4403, 4292, 2010, 4219, 4451, 4112, 4244, 4150, 11431, 4221, 4007, 3249, 16868, 4479, 4150, 3, 6243, 4279, 4219, 12154, 27672, 4070, 3249, 4154, 4147, 27233, 35, 3, 3234, 18, 18, 8784, 4283, 27672, 4073, 3249, 4065, 4150, 35, 3, 11946, 4279, 17164, 8784, 4283, 27672, 4073, 4034, 3123, 4154, 4114, 4116, 4150, 18, 3, 7258, 10238, 27672, 4239, 6304, 6722, 4076, 8553, 3, 19868, 4234, 4641, 4557, 4112, 8538, 4147, 27233, 35, 6270, 8297, 4034, 8830, 4083, 10561, 18, 3, 3311, 4576, 20959, 9826, 6363, 30, 9284, 4073, 21, 4282, 8866, 4070, 4521, 4283, 27233, 35, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 4, 4, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [10238, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [93, 6756, 3, 0, 0, 0], [21, 3, 0, 0, 0, 0], [6363, 30, 9284, 3, 0, 0], [9826, 3, 0, 0, 0, 0], [19868, 4234, 4641, 4557, 3, 0], [21832, 11764, 3, 0, 0, 0], [15532, 4403, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='snowy-hat-8324:ê´€ê´‘_ì‹ë‹¹_11-6', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3, 6698, 4467, 4029, 4034, 9908, 26885, 11684, 25845, 4204, 10561, 18, 2373, 6289, 4279, 4147, 2054, 3249, 4154, 4161, 10397, 35, 3, 2279, 13090, 4192, 2024, 4112, 6249, 4234, 15532, 4403, 4292, 2010, 4219, 4451, 4112, 4244, 4150, 11431, 4221, 4007, 3249, 16868, 4479, 4150, 3, 6243, 4279, 4219, 12154, 27672, 4070, 3249, 4154, 4147, 27233, 35, 3, 3234, 18, 18, 8784, 4283, 27672, 4073, 3249, 4065, 4150, 35, 3, 11946, 4279, 17164, 8784, 4283, 27672, 4073, 4034, 3123, 4154, 4114, 4116, 4150, 18, 3, 7258, 10238, 27672, 4239, 6304, 6722, 4076, 8553, 3, 19868, 4234, 4641, 4557, 4112, 8538, 4147, 27233, 35, 6270, 8297, 4034, 8830, 4083, 10561, 18, 3, 3311, 4576, 20959, 9826, 6363, 30, 9284, 4073, 21, 4282, 8866, 4070, 4521, 4283, 27233, 35, 3, 6259, 17788, 18, 8866, 4086, 4192, 4023, 4829, 10397, 35, 3, 2287, 7149, 10472, 4034, 6477, 11560, 4150, 35, 8117, 4034, 6259, 4283, 27233, 35, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 4, 4, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [10238, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [93, 6756, 3, 0, 0, 0], [21, 3, 0, 0, 0, 0], [6363, 30, 9284, 3, 0, 0], [9826, 3, 0, 0, 0, 0], [19868, 4234, 4641, 4557, 3, 0], [21832, 11764, 3, 0, 0, 0], [15532, 4403, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='snowy-hat-8324:ê´€ê´‘_ì‹ë‹¹_11-7', input_id=[2, 3, 6265, 6672, 4073, 3249, 4034, 8732, 4292, 6722, 4076, 8553, 3, 11655, 4279, 8553, 18, 6336, 4481, 22014, 6771, 4204, 4112, 8538, 4147, 27233, 35, 18790, 4086, 24, 4469, 10749, 14043, 4006, 4073, 4325, 3311, 4112, 6392, 4110, 2734, 4219, 3249, 4576, 6216, 18, 3, 3311, 4116, 4150, 7149, 18790, 4112, 2633, 4151, 4076, 5240, 4050, 6698, 4467, 4029, 4070, 13177, 4479, 4065, 4150, 35, 3, 6698, 4467, 4029, 4034, 9908, 26885, 11684, 25845, 4204, 10561, 18, 2373, 6289, 4279, 4147, 2054, 3249, 4154, 4161, 10397, 35, 3, 2279, 13090, 4192, 2024, 4112, 6249, 4234, 15532, 4403, 4292, 2010, 4219, 4451, 4112, 4244, 4150, 11431, 4221, 4007, 3249, 16868, 4479, 4150, 3, 6243, 4279, 4219, 12154, 27672, 4070, 3249, 4154, 4147, 27233, 35, 3, 3234, 18, 18, 8784, 4283, 27672, 4073, 3249, 4065, 4150, 35, 3, 11946, 4279, 17164, 8784, 4283, 27672, 4073, 4034, 3123, 4154, 4114, 4116, 4150, 18, 3, 7258, 10238, 27672, 4239, 6304, 6722, 4076, 8553, 3, 19868, 4234, 4641, 4557, 4112, 8538, 4147, 27233, 35, 6270, 8297, 4034, 8830, 4083, 10561, 18, 3, 3311, 4576, 20959, 9826, 6363, 30, 9284, 4073, 21, 4282, 8866, 4070, 4521, 4283, 27233, 35, 3, 6259, 17788, 18, 8866, 4086, 4192, 4023, 4829, 10397, 35, 3, 2287, 7149, 10472, 4034, 6477, 11560, 4150, 35, 8117, 4034, 6259, 4283, 27233, 35, 3, 10472, 4034, 6477, 4279, 4219, 3249, 4219, 8117, 4086, 6259, 17788, 18, 2373, 8372, 4279, 4147, 3283, 3249, 4154, 4147, 27233, 35, 3, 6231, 4297, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 4, 4, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6336, 4481, 22014, 6771, 4204, 3], [8732, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [10238, 3, 0, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [93, 6756, 3, 0, 0, 0], [21, 3, 0, 0, 0, 0], [6363, 30, 9284, 3, 0, 0], [9826, 3, 0, 0, 0, 0], [19868, 4234, 4641, 4557, 3, 0], [21832, 11764, 3, 0, 0, 0], [15532, 4403, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [6265, 6672, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0], [21832, 11764, 3, 0, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='polished-poetry-0057:ê´€ê´‘_9-0', input_id=[2, 3, 7596, 4292, 3755, 4228, 18781, 6265, 10806, 4073, 3249, 11649, 4150, 35, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [7596, 3, 0], [21832, 11764, 3], [6265, 10806, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3], [21832, 11764, 3]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='polished-poetry-0057:ê´€ê´‘_9-1', input_id=[2, 3, 7596, 4292, 3755, 4228, 18781, 6265, 10806, 4073, 3249, 11649, 4150, 35, 3, 6265, 10806, 4073, 7596, 4007, 6259, 4283, 2084, 4007, 24874, 28060, 16301, 15550, 12178, 4007, 3249, 4576, 6216, 18, 3, 3158, 2279, 7149, 9068, 3305, 6449, 4076, 8553, 18, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [28060, 16301, 15550, 12178, 3], [7596, 3, 0, 0, 0], [21832, 11764, 3, 0, 0], [6265, 10806, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='polished-poetry-0057:ê´€ê´‘_9-2', input_id=[2, 3, 7596, 4292, 3755, 4228, 18781, 6265, 10806, 4073, 3249, 11649, 4150, 35, 3, 6265, 10806, 4073, 7596, 4007, 6259, 4283, 2084, 4007, 24874, 28060, 16301, 15550, 12178, 4007, 3249, 4576, 6216, 18, 3, 3158, 2279, 7149, 9068, 3305, 6449, 4076, 8553, 18, 3, 28060, 16301, 15550, 12178, 4234, 9068, 4034, 6265, 27439, 10732, 11684, 4096, 10561, 18, 3, 6449, 4076, 4114, 4034, 4396, 4073, 20025, 4294, 18790, 4086, 3305, 6449, 4076, 8553, 18, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [28060, 16301, 15550, 12178, 3], [7596, 3, 0, 0, 0], [21832, 11764, 3, 0, 0], [6265, 10806, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0]], slot_positions=None, domain_id=None),\n",
       " OpenVocabDSTFeature(guid='polished-poetry-0057:ê´€ê´‘_9-3', input_id=[2, 3, 7596, 4292, 3755, 4228, 18781, 6265, 10806, 4073, 3249, 11649, 4150, 35, 3, 6265, 10806, 4073, 7596, 4007, 6259, 4283, 2084, 4007, 24874, 28060, 16301, 15550, 12178, 4007, 3249, 4576, 6216, 18, 3, 3158, 2279, 7149, 9068, 3305, 6449, 4076, 8553, 18, 3, 28060, 16301, 15550, 12178, 4234, 9068, 4034, 6265, 27439, 10732, 11684, 4096, 10561, 18, 3, 6449, 4076, 4114, 4034, 4396, 4073, 20025, 4294, 18790, 4086, 3305, 6449, 4076, 8553, 18, 3, 7258, 18, 20025, 4034, 9141, 26808, 6218, 27738, 26817, 4007, 4219, 18790, 4112, 24, 4469, 10561, 18, 3, 3170, 6851, 17788, 18, 3], segment_id=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], gating_id=[0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], target_ids=[[21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [28060, 16301, 15550, 12178, 3], [7596, 3, 0, 0, 0], [21832, 11764, 3, 0, 0], [6265, 10806, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0], [21832, 11764, 3, 0, 0]], slot_positions=None, domain_id=None)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "==> input ids\n",
    "    í„´ê³¼ í„´ ì‚¬ì´ì—ëŠ” [SEP] í† í°\n",
    "    tokenizer.encode\n",
    "    max_length ê¸¸ì´ ë§ì¶”ê³  ë§ˆì§€ë§‰ì— [CLS] {input_ids} [SEP] ë¡œ ë§Œë“¬\n",
    "'''\n",
    "#train_dataset = train_features\n",
    "train_features = []\n",
    "for example in tqdm(train_example):\n",
    "    # í„´ê³¼ í„´ ì‚¬ì´ì— [SEP]\n",
    "    dialogue_context = \" [SEP] \".join(example.context_turns + example.current_turn)\n",
    "    # tokenizer.encode\n",
    "    input_ids = tokenizer.encode(dialogue_context, add_special_tokens=False)\n",
    "    # max_length ê¸¸ì´ ë§ì¶”ê³  ë§ˆì§€ë§‰ì— [CLS] {input_ids} [SEP] ë¡œ ë§Œë“¬\n",
    "    max_seq_length = 512 - 2 #ë§ˆì§€ë§‰ì— [CLS], [SEP] ë¶™ì¼ ê²ƒì„ ë¹¼ì¤Œ\n",
    "\n",
    "    # ë§Œì•½ max_seq_length ë³´ë‹¤ input_idsê°€ í¬ë©´ ì™¼ìª½ë¶€í„° truncate. ì™¼ìª½ì´ ì˜¤ë˜ëœ ë°œí™”ì´ê¸° ë•Œë¬¸ì´ë‹¤.\n",
    "    if len(input_ids) > max_seq_length:\n",
    "        gap_idx = len(input_ids) - max_seq_length\n",
    "        input_ids = input_ids[gap_idx:]\n",
    "    # ì• ë’¤ì— í† í° ë¶™ì—¬ì£¼ê¸°\n",
    "    input_ids = [tokenizer.cls_token_id] + input_ids + [tokenizer.sep_token_id]\n",
    "    '''\n",
    "    ==> segment ids\n",
    "    bert tokenizerë¥¼ ì‚¬ìš©í•  ë•Œ, ë¬¸ì¥ì„ êµ¬ë¶„í•´ì£¼ê³ ì í•  ë•Œ ì“°ëŠ” id ì´ë‹¤.\n",
    "    '''\n",
    "    firt_sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "    segment_id = [0] * len(input_ids[: firt_sep_idx + 1]) + [1] * len(\n",
    "        input_ids[firt_sep_idx + 1 :]\n",
    "    )\n",
    "    '''\n",
    "    ==> target id\n",
    "    exampleì˜ label(domain-slot-value)ì„ dict(\"domain-slot\":\"value\")ë¡œ ë³€í™˜\n",
    "    slot meta ì „ì²´ slotì— ëŒ€í•˜ì—¬ í•´ë‹¹ stateì˜ value ê°’ì„ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ 0\n",
    "    tokenizer.encode\n",
    "    ë’¤ì— [SEP] í† í° ë¶€ì°©\n",
    "    ê¸¸ì´ë¥¼ ê°™ê²Œ ë§Œë“¤ì–´ ì£¼ê¸° ìœ„í•´ì„œ max_length ë§Œí¼ [PAD] í† í° ë¶€ì°©\n",
    "    '''\n",
    "    state = convert_state_dict(example.label)\n",
    "    gate_ids = []\n",
    "    target_ids = []\n",
    "    for slot in slot_meta:\n",
    "        #slot metaì˜ slotì—ì„œ í˜„ì¬ stateì˜ ê°’ì´ ìˆìœ¼ë©´ í•´ë‹¹ ìŠ¬ë¡¯ì˜ valueë¥¼ ê°€ì ¸ì˜¤ê³  ì—†ìœ¼ë©´ none\n",
    "        value = state.get(slot, \"none\")\n",
    "        #tokenizer.encode\n",
    "        target_id = tokenizer.encode(value, add_special_tokens=False)\n",
    "        target_id += [tokenizer.sep_token_id]\n",
    "        '''\n",
    "        ==> gate id\n",
    "        target idì˜ valueë¥¼ gating2idë¥¼ í†µí•´ indexë¡œ ë³€í™˜\n",
    "        '''\n",
    "        gating2id = {\"none\":0, \"dontcare\":1, \"yes\":2, \"no\":3, \"ptr\":4}\n",
    "        #ì „ì²´ gate_ids, target_idsì— ì¶”ê°€\n",
    "        gate_ids.append(gating2id.get(value, gating2id[\"ptr\"]))\n",
    "        target_ids.append(target_id)\n",
    "    # max length ë§Œí¼ [PAD] ë¶€ì°©\n",
    "    max_length = max(list(map(len, target_ids)))\n",
    "    target_ids = [target_id + [tokenizer.pad_token_id]*(max_length-len(target_id)) for target_id in target_ids]\n",
    "    \n",
    "    #OpenVocabDSTFeature(guid, input_ids, segment_ids, gating_ids, target_ids) ì´ 5ê°œì˜ ë°ì´í„° êµ¬ì„±\n",
    "    train_features.append(OpenVocabDSTFeature(example.guid, input_ids, segment_ids, gate_ids, target_ids))\n",
    "print(f\"ì´ {len(train_features)} ê°œì˜ featuresê°€ ìˆìŠµë‹ˆë‹¤\")\n",
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa4749-f1e7-4e67-a5cb-ede9e124ed6a",
   "metadata": {},
   "source": [
    "### 2. TRADE Model Architecture\n",
    "TRADE ëª¨ë“ˆì€ ì´ 3ê°€ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.\n",
    "- Utterance encoder - Bidirection GRU based encoder(Bert ê°€ëŠ¥)\n",
    "- Slot(State) generator - GRU based decoder(transformer decoder ê°€ëŠ¥)\n",
    "- Slot gate - pointer generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee1746b1-d3d2-43ec-86a1-e9242923d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utterance encoder\n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layer, dropout, proj_dim=None, pad_idx=0):\n",
    "        super(GRUEncoder, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
    "        if proj_dim:\n",
    "            self.proj_layer = nn.Linear(d_model, proj_dim, bias=False)\n",
    "        else:\n",
    "            self.proj_layer = None\n",
    "\n",
    "        self.d_model = proj_dim if proj_dim else d_model\n",
    "        self.gru = nn.GRU(\n",
    "            self.d_model,\n",
    "            self.d_model,\n",
    "            n_layer,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        mask = input_ids.eq(self.pad_idx).unsqueeze(-1)\n",
    "        x = self.embed(input_ids)\n",
    "        if self.proj_layer:\n",
    "            x = self.proj_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        o, h = self.gru(x)\n",
    "        o = o.masked_fill(mask, 0.0)\n",
    "        # bidirectional ì´ë¼ ë‘ê°œ ì´ì–´ì£¼ëŠ”ê±°\n",
    "        output = o[:, :, : self.d_model] + o[:, :, self.d_model :]\n",
    "        hidden = h[0] + h[1]  # n_layer ê³ ë ¤\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3cdcc3c0-3e87-45ab-a865-8d545c081035",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlotGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, hidden_size, dropout, n_gate, proj_dim=None, pad_idx=0\n",
    "    ):\n",
    "        super(SlotGenerator, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = nn.Embedding(\n",
    "            vocab_size, hidden_size, padding_idx=pad_idx\n",
    "        )  # shared with encoder\n",
    "\n",
    "        if proj_dim:\n",
    "            self.proj_layer = nn.Linear(hidden_size, proj_dim, bias=False)\n",
    "        else:\n",
    "            self.proj_layer = None\n",
    "        self.hidden_size = proj_dim if proj_dim else hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            self.hidden_size, self.hidden_size, 1, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.n_gate = n_gate\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.w_gen = nn.Linear(self.hidden_size * 3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.w_gate = nn.Linear(self.hidden_size, n_gate)\n",
    "\n",
    "    def set_slot_idx(self, slot_vocab_idx):\n",
    "        whole = []\n",
    "        max_length = max(map(len, slot_vocab_idx))\n",
    "        for idx in slot_vocab_idx:\n",
    "            if len(idx) < max_length:\n",
    "                gap = max_length - len(idx)\n",
    "                idx.extend([self.pad_idx] * gap)\n",
    "            whole.append(idx)\n",
    "        self.slot_embed_idx = whole  # torch.LongTensor(whole)\n",
    "\n",
    "    def embedding(self, x):\n",
    "        x = self.embed(x)\n",
    "        if self.proj_layer:\n",
    "            x = self.proj_layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, encoder_output, hidden, input_masks, max_len, teacher=None\n",
    "    ):\n",
    "        print(input_masks.shape)\n",
    "        input_masks = input_masks.ne(1) #input mask ë°˜ì „\n",
    "        print(input_masks.shape) # \n",
    "        # J, slot_meta : key : [domain, slot] ex> LongTensor([1,2])\n",
    "        # J,2\n",
    "        batch_size = encoder_output.size(0)\n",
    "        slot = torch.tensor(\n",
    "            self.slot_embed_idx, device=input_ids.device, dtype=torch.int64\n",
    "        )  ##\n",
    "        slot_e = torch.sum(self.embedding(slot), 1)  # J,d\n",
    "        J = slot_e.size(0)\n",
    "\n",
    "        all_point_outputs = torch.zeros(\n",
    "            batch_size, J, max_len, self.vocab_size, device=input_ids.device\n",
    "        )\n",
    "\n",
    "        # Parallel Decoding\n",
    "        w = slot_e.repeat(batch_size, 1).unsqueeze(1)\n",
    "        hidden = hidden.repeat_interleave(J, dim=1)\n",
    "        encoder_output = encoder_output.repeat_interleave(J, dim=0)\n",
    "        input_ids = input_ids.repeat_interleave(J, dim=0)\n",
    "        input_masks = input_masks.repeat_interleave(J, dim=0)\n",
    "        for k in range(max_len):\n",
    "            w = self.dropout(w)\n",
    "            _, hidden = self.gru(w, hidden)  # 1,B,D\n",
    "\n",
    "            # B,T,D * B,D,1 => B,T\n",
    "            attn_e = torch.bmm(encoder_output, hidden.permute(1, 2, 0))  # B,T,1\n",
    "            attn_e = attn_e.squeeze(-1).masked_fill(input_masks, -1e4)\n",
    "            attn_history = F.softmax(attn_e, -1)  # B,T\n",
    "\n",
    "            if self.proj_layer:\n",
    "                hidden_proj = torch.matmul(hidden, self.proj_layer.weight)\n",
    "            else:\n",
    "                hidden_proj = hidden\n",
    "\n",
    "            # B,D * D,V => B,V\n",
    "            attn_v = torch.matmul(\n",
    "                hidden_proj.squeeze(0), self.embed.weight.transpose(0, 1)\n",
    "            )  # B,V\n",
    "            attn_vocab = F.softmax(attn_v, -1)\n",
    "\n",
    "            # B,1,T * B,T,D => B,1,D\n",
    "            context = torch.bmm(attn_history.unsqueeze(1), encoder_output)  # B,1,D\n",
    "            p_gen = self.sigmoid(\n",
    "                self.w_gen(torch.cat([w, hidden.transpose(0, 1), context], -1))\n",
    "            )  # B,1\n",
    "            p_gen = p_gen.squeeze(-1)\n",
    "\n",
    "            p_context_ptr = torch.zeros_like(attn_vocab, device=input_ids.device)\n",
    "            p_context_ptr.scatter_add_(1, input_ids, attn_history)  # copy B,V\n",
    "            p_final = p_gen * attn_vocab + (1 - p_gen) * p_context_ptr  # B,V\n",
    "            _, w_idx = p_final.max(-1)\n",
    "\n",
    "            if teacher is not None:\n",
    "                w = (\n",
    "                    self.embedding(teacher[:, :, k])\n",
    "                    # .transpose(0, 1)\n",
    "                    .reshape(batch_size * J, 1, -1)\n",
    "                )\n",
    "            else:\n",
    "                w = self.embedding(w_idx).unsqueeze(1)  # B,1,D\n",
    "            if k == 0:\n",
    "                gated_logit = self.w_gate(context.squeeze(1))  # B,3\n",
    "                all_gate_outputs = gated_logit.view(batch_size, J, self.n_gate)\n",
    "            all_point_outputs[:, :, k, :] = p_final.view(batch_size, J, self.vocab_size)\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "330c9ee0-8cfc-4ff7-b013-da044caf67d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J X emb_dim : torch.Size([45, 4])\n",
      "J X hidden_dim : torch.Size([45, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([1, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer)\n",
    "hidden_dim = 768\n",
    "n_layer = 1\n",
    "dropout = 0.1\n",
    "n_gate = 5\n",
    "max_len = 512\n",
    "#dataset í˜•ì‹ìœ¼ë¡œ ë°”ê¾¸ì–´ì¤Œ\n",
    "train_data = WOSDataset(train_features)\n",
    "train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=1,\n",
    "        collate_fn=processor.collate_fn,\n",
    "    )\n",
    "for batch in train_loader:\n",
    "    #word2vec ê³¼ charì„ ì“°ëŠ” ê²ƒì´ ì•„ë‹Œ, torch embedding ì‚¬ìš©\n",
    "    input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = batch\n",
    "    utterance_encoder = GRUEncoder(vocab_size, hidden_dim, n_layer, dropout)\n",
    "    output, hidden = utterance_encoder(input_ids) # 1 X encoder_max_seq_len X hidden_dim (1 X 512 X 768)\n",
    "    \n",
    "    #Slot generator\n",
    "    '''\n",
    "    ==> tokenized slot meta\n",
    "    tokenizer.encode\n",
    "    '''\n",
    "    tokenized_slot_meta = []\n",
    "    for slot in slot_meta:\n",
    "        tokenized_slot_meta.append(\n",
    "            #í•˜ì´í‘¼ì„ ì œê±°í•˜ê³  tokenizer.encdoing\n",
    "            tokenizer.encode(slot.replace(\"-\", \" \"), add_special_tokens=False)\n",
    "        )\n",
    "    slot_generator = SlotGenerator(vocab_size, hidden_dim, dropout, n_gate)\n",
    "    slot_generator.set_slot_idx(tokenized_slot_meta)\n",
    "    slot_generator.embed.weight = utterance_encoder.embed.weight\n",
    "    if slot_generator.proj_layer:\n",
    "        slot_generator.proj_layer.weight = utterance_encoder.proj_layer.weight\n",
    "    \n",
    "    slot = torch.LongTensor(slot_generator.slot_embed_idx).to(input_ids.device) # J X emb_dim\n",
    "    print(f\"J X emb_dim : {slot.shape}\")\n",
    "    slot_e = torch.sum(slot_generator.embed(slot), 1) # J X hidden_dim\n",
    "    print(f\"J X hidden_dim : {slot_e.shape}\")\n",
    "    J = slot_e.size(0)\n",
    "    #print(slot_generator(input_ids, output, hidden.unsqueeze(0), input_masks, target_ids.size(-1), None))\n",
    "    \n",
    "    #zero tensor initialize\n",
    "    batch_size = 1\n",
    "    all_point_outputs = torch.zeros(J, batch_size, max_len, vocab_size).to(input_ids.device)\n",
    "    all_gate_outputs = torch.zeros(J, batch_size, n_gate).to(input_ids.device)\n",
    "    \n",
    "    for j in range(J):\n",
    "        print(slot_e[j].shape) # hidden\n",
    "        w = slot_e[j].expand(batch_size, 1, hidden_dim) #b X 1 X hidden\n",
    "        print(w.shape)\n",
    "        slot_value = []\n",
    "        for k in range(max_len):\n",
    "            w = \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d83a03-fcac-4a7a-adc0-107b12a70a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}